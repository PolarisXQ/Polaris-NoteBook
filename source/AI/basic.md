# Basic Concepts for Machine Learning

## Naive Bayes

朴素贝叶斯(naive Bayes)算法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布。然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。不同于其他分类器，朴素贝叶斯是一种基于概率理论的分类算法；总体来说，朴素贝叶斯原理和实现都比较简单，学习和预测效率较高，是一种经典而常用的分类算法。其中的朴素（naive）是指的对于数据集中的各个特征（feature）都有较强的独立性假设，并未将特征之间的相关性考虑其中。

其实就是在特征独立的假设下，根据先验概率（训练集中各类别出现的概率）和后验概率（训练集中各类别下各个特征出现的概率）来计算出输入数据属于各个类别的概率，最终选择概率最大的类别作为分类结果。

## Decision Tree

决策树是一种基本的分类与回归方法。决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。

决策树学习通常包括三个步骤：特征选择、树的生成和树的剪枝。决策树的生成是一个递归过程，通过选择最优特征并分裂数据集，直到满足某个条件为止。决策树的剪枝是为了防止过拟合。

## Support Vector Machine

支持向量机（Support Vector Machine, SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使得SVM具有良好的泛化能力。SVM的学习策略是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。

## K-Nearest Neighbors

K-近邻算法（K-Nearest Neighbors, KNN）是一种基本的分类和回归方法。KNN算法的基本思想是：对于一个未知样本，找出与其最接近的K个样本，然后根据这K个样本的标签，通过多数投票的方式来决定未知样本的类别。KNN算法的优点是简单易懂，缺点是计算复杂度高，尤其